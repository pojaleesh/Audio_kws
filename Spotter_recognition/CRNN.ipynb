{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, TimeDistributed\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, MaxPool2D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "from service.data_augmentation import make_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(os.path.abspath('Target_words_dataframe'))\n",
    "df_unknown = pd.read_csv(os.path.abspath('Unknown_words_dataframe'))\n",
    "df = pd.read_csv(os.path.abspath('full_df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.drop(columns=['Unnamed: 0'], axis=1)\n",
    "df_unknown = df_unknown.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/yes/988...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/yes/93e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/yes/a75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/yes/627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/yes/439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>41034</td>\n",
       "      <td>unkown</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/four/93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>41035</td>\n",
       "      <td>unkown</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/four/0c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>41036</td>\n",
       "      <td>unkown</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/four/23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>41037</td>\n",
       "      <td>unkown</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/four/17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64720</th>\n",
       "      <td>41038</td>\n",
       "      <td>unkown</td>\n",
       "      <td>/Users/mbassalaev/Desktop/spotter_data/four/c6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64721 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0    word                                               path\n",
       "0               0     yes  /Users/mbassalaev/Desktop/spotter_data/yes/988...\n",
       "1               1     yes  /Users/mbassalaev/Desktop/spotter_data/yes/93e...\n",
       "2               2     yes  /Users/mbassalaev/Desktop/spotter_data/yes/a75...\n",
       "3               3     yes  /Users/mbassalaev/Desktop/spotter_data/yes/627...\n",
       "4               4     yes  /Users/mbassalaev/Desktop/spotter_data/yes/439...\n",
       "...           ...     ...                                                ...\n",
       "64716       41034  unkown  /Users/mbassalaev/Desktop/spotter_data/four/93...\n",
       "64717       41035  unkown  /Users/mbassalaev/Desktop/spotter_data/four/0c...\n",
       "64718       41036  unkown  /Users/mbassalaev/Desktop/spotter_data/four/23...\n",
       "64719       41037  unkown  /Users/mbassalaev/Desktop/spotter_data/four/17...\n",
       "64720       41038  unkown  /Users/mbassalaev/Desktop/spotter_data/four/c6...\n",
       "\n",
       "[64721 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.abspath('../../Data_spotter_mfcc_40')\n",
    "outfile = open(filename,'rb')\n",
    "X = pickle.load(outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(Model, model_name):\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    Model.save(model_path)\n",
    "    print('Save model and weights at %s ' % model_path)\n",
    "\n",
    "    model_json = Model.to_json()\n",
    "    with open(\"model_json.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_history(model_history, model_history_name):\n",
    "    filename = 'saved_models_history/' + model_history_name\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(model_history, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model, X, y, classes):\n",
    "    model_predictions = model.predict(X).argmax(axis=1)\n",
    "    true_predictions = y.argmax(axis=1)\n",
    "    return sklearn.metrics.classification_report(true_predictions, model_predictions, target_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X\n",
    "                                                    , df.word\n",
    "                                                    , test_size=6464\n",
    "                                                    , train_size = 58240\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size = (58240, 40, 61)\n",
      "Y_train size = (58240,)\n",
      "X_test size = (6464, 40, 61)\n",
      "Y_test size = (6464,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train size = {X_train.shape}')\n",
    "print(f'Y_train size = {Y_train.shape}')\n",
    "print(f'X_test size = {X_test.shape}')\n",
    "print(f'Y_test size = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes =  ['down' 'go' 'left' 'no' 'off' 'on' 'right' 'stop' 'unkown' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "Y_train = np_utils.to_categorical(lb.fit_transform(Y_train))\n",
    "Y_test = np_utils.to_categorical(lb.fit_transform(Y_test))\n",
    "print('classes = ', lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size = (58240, 40, 61, 1)\n",
      "X_test size = (6464, 40, 61, 1)\n",
      "Y_train size = (58240, 11)\n",
      "Y_test size = (6464, 11)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "print(f'X_train size = {X_train.shape}')\n",
    "print(f'X_test size = {X_test.shape}')\n",
    "print(f'Y_train size = {Y_train.shape}')\n",
    "print(f'Y_test size = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRNN_model(input_shape, nclass):\n",
    "    \n",
    "    input_ = Input(input_shape, batch_size=64)\n",
    "    \n",
    "    X = Conv2D(16, kernel_size=(3, 3), activation=\"relu\", dilation_rate=(1, 1), strides=(1, 1))(input_)\n",
    "    X = Conv2D(16, kernel_size=(5, 3), activation=\"relu\", dilation_rate=(1, 1), strides=(1, 1))(X)\n",
    "    \n",
    "    shape = X.shape\n",
    "    X = tf.keras.layers.Reshape((-1, shape[2] * shape[3]))(X)\n",
    "    \n",
    "    X = GRU(units = 256, return_sequences=0, stateful=1)(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(rate=0.1)(X)\n",
    "    \n",
    "    X = Dense(128, activation=\"linear\")(X)\n",
    "    X = Dense(256, activation=\"relu\")(X)\n",
    "    \n",
    "    output_ = Dense(nclass, activation='softmax')(X)\n",
    "    \n",
    "    ret_model = Model(inputs = input_, outputs=output_)\n",
    "    \n",
    "    return ret_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRNN_model((40, 61, 1), len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(64, 40, 61, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (64, 38, 59, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (64, 34, 57, 16)          3856      \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (64, 34, 912)             0         \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (64, 256)                 898560    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (64, 256)                 0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (64, 256)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (64, 128)                 32896     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (64, 256)                 33024     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (64, 11)                  2827      \n",
      "=================================================================\n",
      "Total params: 971,323\n",
      "Trainable params: 971,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(0.001)\n",
    "model.compile(optimizer = opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "train_acc_metric = keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "101/101 [==============================] - 5s 42ms/step - loss: 1.5050 - accuracy: 0.6425\n",
      "Current step: 50\n",
      "Test loss and acc: 1.5449 0.6303\n",
      "Training loss and acc: 1.7412 0.6486\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.5096 - accuracy: 0.6303\n",
      "Current step: 100\n",
      "Test loss and acc: 1.5096 0.6303\n",
      "Training loss and acc: 1.3888 0.6463\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.5472 - accuracy: 0.6303\n",
      "Current step: 150\n",
      "Test loss and acc: 1.5472 0.6303\n",
      "Training loss and acc: 1.5103 0.6448\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4971 - accuracy: 0.6303\n",
      "Current step: 200\n",
      "Test loss and acc: 1.4971 0.6303\n",
      "Training loss and acc: 1.3139 0.6395\n",
      "Seen so far: 12864 samples\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x172235ed0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Users/mbassalaev/Desktop/audio_project/venv37/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\", line 4489, in <genexpr>\n",
      "    ta.write(time, out) for ta, out in zip(output_ta_t, flat_output))  File \"/Users/mbassalaev/Desktop/audio_project/venv37/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py\", line 249, in wrapped\n",
      "    error_in_function=error_in_function)\n",
      "==================================\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.5078 - accuracy: 0.6303\n",
      "Current step: 250\n",
      "Test loss and acc: 1.5078 0.6303\n",
      "Training loss and acc: 1.8931 0.6377\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4970 - accuracy: 0.6303\n",
      "Current step: 300\n",
      "Test loss and acc: 1.4970 0.6303\n",
      "Training loss and acc: 1.5388 0.6365\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4824 - accuracy: 0.6303\n",
      "Current step: 350\n",
      "Test loss and acc: 1.4824 0.6303\n",
      "Training loss and acc: 1.5438 0.6358\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4970 - accuracy: 0.6303\n",
      "Current step: 400\n",
      "Test loss and acc: 1.4970 0.6303\n",
      "Training loss and acc: 1.3704 0.6365\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.4549 - accuracy: 0.6317\n",
      "Current step: 450\n",
      "Test loss and acc: 1.4549 0.6317\n",
      "Training loss and acc: 1.4235 0.6372\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4780 - accuracy: 0.6304\n",
      "Current step: 500\n",
      "Test loss and acc: 1.4780 0.6304\n",
      "Training loss and acc: 1.5314 0.6376\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4414 - accuracy: 0.6317\n",
      "Current step: 550\n",
      "Test loss and acc: 1.4414 0.6317\n",
      "Training loss and acc: 1.4759 0.6372\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4528 - accuracy: 0.6309\n",
      "Current step: 600\n",
      "Test loss and acc: 1.4528 0.6309\n",
      "Training loss and acc: 1.4412 0.6368\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.4080 - accuracy: 0.6324\n",
      "Current step: 650\n",
      "Test loss and acc: 1.4080 0.6324\n",
      "Training loss and acc: 1.4053 0.6360\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3791 - accuracy: 0.6355\n",
      "Current step: 700\n",
      "Test loss and acc: 1.3791 0.6355\n",
      "Training loss and acc: 1.2383 0.6362\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3772 - accuracy: 0.6338\n",
      "Current step: 750\n",
      "Test loss and acc: 1.3772 0.6338\n",
      "Training loss and acc: 1.2393 0.6357\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3671 - accuracy: 0.6344\n",
      "Current step: 800\n",
      "Test loss and acc: 1.3671 0.6344\n",
      "Training loss and acc: 1.3757 0.6351\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.3724 - accuracy: 0.6358\n",
      "Current step: 850\n",
      "Test loss and acc: 1.3724 0.6358\n",
      "Training loss and acc: 1.6721 0.6342\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3532 - accuracy: 0.6335\n",
      "Current step: 900\n",
      "Test loss and acc: 1.3532 0.6335\n",
      "Training loss and acc: 1.5296 0.6350\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 1\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3542 - accuracy: 0.6363\n",
      "Current step: 50\n",
      "Test loss and acc: 1.3542 0.6363\n",
      "Training loss and acc: 1.4504 0.6599\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3241 - accuracy: 0.6338\n",
      "Current step: 100\n",
      "Test loss and acc: 1.3241 0.6338\n",
      "Training loss and acc: 1.0613 0.6525\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.3447 - accuracy: 0.6344\n",
      "Current step: 150\n",
      "Test loss and acc: 1.3447 0.6344\n",
      "Training loss and acc: 1.2908 0.6501\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3143 - accuracy: 0.6375\n",
      "Current step: 200\n",
      "Test loss and acc: 1.3143 0.6375\n",
      "Training loss and acc: 1.1539 0.6447\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.3096 - accuracy: 0.6414\n",
      "Current step: 250\n",
      "Test loss and acc: 1.3096 0.6414\n",
      "Training loss and acc: 1.4271 0.6429\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.3141 - accuracy: 0.6372\n",
      "Current step: 300\n",
      "Test loss and acc: 1.3141 0.6372\n",
      "Training loss and acc: 1.3393 0.6428\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.3107 - accuracy: 0.6386\n",
      "Current step: 350\n",
      "Test loss and acc: 1.3107 0.6386\n",
      "Training loss and acc: 1.3914 0.6429\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.2807 - accuracy: 0.6403\n",
      "Current step: 400\n",
      "Test loss and acc: 1.2807 0.6403\n",
      "Training loss and acc: 1.2301 0.6440\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.2843 - accuracy: 0.6290\n",
      "Current step: 450\n",
      "Test loss and acc: 1.2843 0.6290\n",
      "Training loss and acc: 1.2758 0.6450\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.2865 - accuracy: 0.6460\n",
      "Current step: 500\n",
      "Test loss and acc: 1.2865 0.6460\n",
      "Training loss and acc: 1.1959 0.6453\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.2477 - accuracy: 0.6425\n",
      "Current step: 550\n",
      "Test loss and acc: 1.2477 0.6425\n",
      "Training loss and acc: 1.3120 0.6452\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.2332 - accuracy: 0.6454\n",
      "Current step: 600\n",
      "Test loss and acc: 1.2332 0.6454\n",
      "Training loss and acc: 1.2255 0.6453\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.2283 - accuracy: 0.6450\n",
      "Current step: 650\n",
      "Test loss and acc: 1.2283 0.6450\n",
      "Training loss and acc: 1.0664 0.6447\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.2033 - accuracy: 0.6536\n",
      "Current step: 700\n",
      "Test loss and acc: 1.2033 0.6536\n",
      "Training loss and acc: 1.1207 0.6452\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.1761 - accuracy: 0.6581\n",
      "Current step: 750\n",
      "Test loss and acc: 1.1761 0.6581\n",
      "Training loss and acc: 1.0596 0.6455\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.1987 - accuracy: 0.6601\n",
      "Current step: 800\n",
      "Test loss and acc: 1.1987 0.6601\n",
      "Training loss and acc: 1.1311 0.6458\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.1332 - accuracy: 0.6597\n",
      "Current step: 850\n",
      "Test loss and acc: 1.1332 0.6597\n",
      "Training loss and acc: 1.2743 0.6461\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.1008 - accuracy: 0.6714\n",
      "Current step: 900\n",
      "Test loss and acc: 1.1008 0.6714\n",
      "Training loss and acc: 1.2114 0.6472\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 2\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.0932 - accuracy: 0.6771\n",
      "Current step: 50\n",
      "Test loss and acc: 1.0932 0.6771\n",
      "Training loss and acc: 1.0609 0.6893\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.0685 - accuracy: 0.6697\n",
      "Current step: 100\n",
      "Test loss and acc: 1.0685 0.6697\n",
      "Training loss and acc: 0.8802 0.6873\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 1.0187 - accuracy: 0.6884\n",
      "Current step: 150\n",
      "Test loss and acc: 1.0187 0.6884\n",
      "Training loss and acc: 1.1071 0.6865\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.0087 - accuracy: 0.6943\n",
      "Current step: 200\n",
      "Test loss and acc: 1.0087 0.6943\n",
      "Training loss and acc: 0.9144 0.6850\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 1.0178 - accuracy: 0.6901\n",
      "Current step: 250\n",
      "Test loss and acc: 1.0178 0.6901\n",
      "Training loss and acc: 1.0853 0.6856\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.9386 - accuracy: 0.7078\n",
      "Current step: 300\n",
      "Test loss and acc: 0.9386 0.7078\n",
      "Training loss and acc: 1.0147 0.6869\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.9341 - accuracy: 0.7045\n",
      "Current step: 350\n",
      "Test loss and acc: 0.9341 0.7045\n",
      "Training loss and acc: 0.8719 0.6901\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8816 - accuracy: 0.7260\n",
      "Current step: 400\n",
      "Test loss and acc: 0.8816 0.7260\n",
      "Training loss and acc: 0.8257 0.6947\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.9182 - accuracy: 0.7088\n",
      "Current step: 450\n",
      "Test loss and acc: 0.9182 0.7088\n",
      "Training loss and acc: 0.8970 0.6982\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8827 - accuracy: 0.7147\n",
      "Current step: 500\n",
      "Test loss and acc: 0.8827 0.7147\n",
      "Training loss and acc: 0.7648 0.7014\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8461 - accuracy: 0.7321\n",
      "Current step: 550\n",
      "Test loss and acc: 0.8461 0.7321\n",
      "Training loss and acc: 0.8197 0.7039\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8193 - accuracy: 0.7325\n",
      "Current step: 600\n",
      "Test loss and acc: 0.8193 0.7325\n",
      "Training loss and acc: 0.6791 0.7067\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8281 - accuracy: 0.7342\n",
      "Current step: 650\n",
      "Test loss and acc: 0.8281 0.7342\n",
      "Training loss and acc: 0.6206 0.7089\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8163 - accuracy: 0.7410\n",
      "Current step: 700\n",
      "Test loss and acc: 0.8163 0.7410\n",
      "Training loss and acc: 0.6594 0.7117\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7874 - accuracy: 0.7435\n",
      "Current step: 750\n",
      "Test loss and acc: 0.7874 0.7435\n",
      "Training loss and acc: 0.6819 0.7138\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7605 - accuracy: 0.7485\n",
      "Current step: 800\n",
      "Test loss and acc: 0.7605 0.7485\n",
      "Training loss and acc: 0.6470 0.7163\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7585 - accuracy: 0.7550\n",
      "Current step: 850\n",
      "Test loss and acc: 0.7585 0.7550\n",
      "Training loss and acc: 0.8063 0.7190\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7435 - accuracy: 0.7568\n",
      "Current step: 900\n",
      "Test loss and acc: 0.7435 0.7568\n",
      "Training loss and acc: 0.7442 0.7212\n",
      "Seen so far: 57664 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        # Log every 50 batches.\n",
    "        if step % 50 == 0 and step > 0:\n",
    "            test_loss_acc = model.evaluate(X_test, Y_test, batch_size=64)\n",
    "            train_loss_acc = float(loss_value), float(train_acc_metric.result()) \n",
    "            test_loss.append(test_loss_acc[0])\n",
    "            test_acc.append(test_loss_acc[1])\n",
    "            train_loss.append(train_loss_acc[0])\n",
    "            train_acc.append(train_loss_acc[1])\n",
    "            print(\"Current step: %d\" % step)\n",
    "            print(\"Test loss and acc: %.4f %.4f\" % (test_loss_acc[0], test_loss_acc[1]))\n",
    "            print(\"Training loss and acc: %.4f %.4f\" % (float(train_loss_acc[0]), float(train_loss_acc[1])))\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "101/101 [==============================] - 5s 45ms/step - loss: 0.7573 - accuracy: 0.7534\n",
      "Current step: 50\n",
      "Test loss and acc: 0.7573 0.7534\n",
      "Training loss and acc: 0.7065 0.7840\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7090 - accuracy: 0.7658\n",
      "Current step: 100\n",
      "Test loss and acc: 0.7090 0.7658\n",
      "Training loss and acc: 0.4645 0.7856\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7061 - accuracy: 0.7686\n",
      "Current step: 150\n",
      "Test loss and acc: 0.7061 0.7686\n",
      "Training loss and acc: 0.8381 0.7827\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7293 - accuracy: 0.7628\n",
      "Current step: 200\n",
      "Test loss and acc: 0.7293 0.7628\n",
      "Training loss and acc: 0.5748 0.7849\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7865 - accuracy: 0.7539\n",
      "Current step: 250\n",
      "Test loss and acc: 0.7865 0.7539\n",
      "Training loss and acc: 0.7017 0.7854\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6751 - accuracy: 0.7775\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6751 0.7775\n",
      "Training loss and acc: 0.5682 0.7838\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6992 - accuracy: 0.7686\n",
      "Current step: 350\n",
      "Test loss and acc: 0.6992 0.7686\n",
      "Training loss and acc: 0.6598 0.7865\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6826 - accuracy: 0.7789\n",
      "Current step: 400\n",
      "Test loss and acc: 0.6826 0.7789\n",
      "Training loss and acc: 0.7000 0.7879\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6673 - accuracy: 0.7828\n",
      "Current step: 450\n",
      "Test loss and acc: 0.6673 0.7828\n",
      "Training loss and acc: 0.5866 0.7900\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6560 - accuracy: 0.7856\n",
      "Current step: 500\n",
      "Test loss and acc: 0.6560 0.7856\n",
      "Training loss and acc: 0.5061 0.7923\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6783 - accuracy: 0.7862\n",
      "Current step: 550\n",
      "Test loss and acc: 0.6783 0.7862\n",
      "Training loss and acc: 0.6131 0.7951\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6998 - accuracy: 0.7717\n",
      "Current step: 600\n",
      "Test loss and acc: 0.6998 0.7717\n",
      "Training loss and acc: 0.5121 0.7971\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6960 - accuracy: 0.7819\n",
      "Current step: 650\n",
      "Test loss and acc: 0.6960 0.7819\n",
      "Training loss and acc: 0.3799 0.7980\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6951 - accuracy: 0.7724\n",
      "Current step: 700\n",
      "Test loss and acc: 0.6951 0.7724\n",
      "Training loss and acc: 0.4507 0.7996\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6513 - accuracy: 0.7859\n",
      "Current step: 750\n",
      "Test loss and acc: 0.6513 0.7859\n",
      "Training loss and acc: 0.5222 0.8012\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6449 - accuracy: 0.7907\n",
      "Current step: 800\n",
      "Test loss and acc: 0.6449 0.7907\n",
      "Training loss and acc: 0.5553 0.8026\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6674 - accuracy: 0.7777\n",
      "Current step: 850\n",
      "Test loss and acc: 0.6674 0.7777\n",
      "Training loss and acc: 0.6978 0.8039\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6488 - accuracy: 0.7912\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6488 0.7912\n",
      "Training loss and acc: 0.4798 0.8053\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 1\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6764 - accuracy: 0.7791\n",
      "Current step: 50\n",
      "Test loss and acc: 0.6764 0.7791\n",
      "Training loss and acc: 0.4277 0.8480\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6261 - accuracy: 0.7990\n",
      "Current step: 100\n",
      "Test loss and acc: 0.6261 0.7990\n",
      "Training loss and acc: 0.3968 0.8453\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6309 - accuracy: 0.7953\n",
      "Current step: 150\n",
      "Test loss and acc: 0.6309 0.7953\n",
      "Training loss and acc: 0.5635 0.8452\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6387 - accuracy: 0.7918\n",
      "Current step: 200\n",
      "Test loss and acc: 0.6387 0.7918\n",
      "Training loss and acc: 0.3802 0.8489\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6835 - accuracy: 0.7871\n",
      "Current step: 250\n",
      "Test loss and acc: 0.6835 0.7871\n",
      "Training loss and acc: 0.4250 0.8483\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6208 - accuracy: 0.8009\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6208 0.8009\n",
      "Training loss and acc: 0.3878 0.8470\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6417 - accuracy: 0.7947\n",
      "Current step: 350\n",
      "Test loss and acc: 0.6417 0.7947\n",
      "Training loss and acc: 0.4283 0.8493\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6276 - accuracy: 0.8023\n",
      "Current step: 400\n",
      "Test loss and acc: 0.6276 0.8023\n",
      "Training loss and acc: 0.5882 0.8510\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6492 - accuracy: 0.7901\n",
      "Current step: 450\n",
      "Test loss and acc: 0.6492 0.7901\n",
      "Training loss and acc: 0.2903 0.8526\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7475 - accuracy: 0.7785\n",
      "Current step: 500\n",
      "Test loss and acc: 0.7475 0.7785\n",
      "Training loss and acc: 0.4099 0.8535\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6488 - accuracy: 0.8049\n",
      "Current step: 550\n",
      "Test loss and acc: 0.6488 0.8049\n",
      "Training loss and acc: 0.5020 0.8547\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6944 - accuracy: 0.7919\n",
      "Current step: 600\n",
      "Test loss and acc: 0.6944 0.7919\n",
      "Training loss and acc: 0.4254 0.8562\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6546 - accuracy: 0.7980\n",
      "Current step: 650\n",
      "Test loss and acc: 0.6546 0.7980\n",
      "Training loss and acc: 0.3616 0.8566\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6656 - accuracy: 0.7987\n",
      "Current step: 700\n",
      "Test loss and acc: 0.6656 0.7987\n",
      "Training loss and acc: 0.1670 0.8574\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6550 - accuracy: 0.7952\n",
      "Current step: 750\n",
      "Test loss and acc: 0.6550 0.7952\n",
      "Training loss and acc: 0.5116 0.8586\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6991 - accuracy: 0.7918\n",
      "Current step: 800\n",
      "Test loss and acc: 0.6991 0.7918\n",
      "Training loss and acc: 0.3722 0.8589\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.6670 - accuracy: 0.7952\n",
      "Current step: 850\n",
      "Test loss and acc: 0.6670 0.7952\n",
      "Training loss and acc: 0.4912 0.8594\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.6708 - accuracy: 0.7865\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6708 0.7865\n",
      "Training loss and acc: 0.3815 0.8595\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 2\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.6825 - accuracy: 0.8032\n",
      "Current step: 50\n",
      "Test loss and acc: 0.6825 0.8032\n",
      "Training loss and acc: 0.3077 0.8839\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6689 - accuracy: 0.7989\n",
      "Current step: 100\n",
      "Test loss and acc: 0.6689 0.7989\n",
      "Training loss and acc: 0.2762 0.8830\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6904 - accuracy: 0.7904\n",
      "Current step: 150\n",
      "Test loss and acc: 0.6904 0.7904\n",
      "Training loss and acc: 0.4378 0.8821\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6856 - accuracy: 0.8035\n",
      "Current step: 200\n",
      "Test loss and acc: 0.6856 0.8035\n",
      "Training loss and acc: 0.2131 0.8851\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6873 - accuracy: 0.7969\n",
      "Current step: 250\n",
      "Test loss and acc: 0.6873 0.7969\n",
      "Training loss and acc: 0.2730 0.8826\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.6593 - accuracy: 0.8018\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6593 0.8018\n",
      "Training loss and acc: 0.2887 0.8810\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6784 - accuracy: 0.8074\n",
      "Current step: 350\n",
      "Test loss and acc: 0.6784 0.8074\n",
      "Training loss and acc: 0.2631 0.8831\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6984 - accuracy: 0.7946\n",
      "Current step: 400\n",
      "Test loss and acc: 0.6984 0.7946\n",
      "Training loss and acc: 0.4953 0.8838\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.7002 - accuracy: 0.7950\n",
      "Current step: 450\n",
      "Test loss and acc: 0.7002 0.7950\n",
      "Training loss and acc: 0.2547 0.8841\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7049 - accuracy: 0.8068\n",
      "Current step: 500\n",
      "Test loss and acc: 0.7049 0.8068\n",
      "Training loss and acc: 0.1953 0.8854\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7008 - accuracy: 0.8020\n",
      "Current step: 550\n",
      "Test loss and acc: 0.7008 0.8020\n",
      "Training loss and acc: 0.4288 0.8865\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7086 - accuracy: 0.8077\n",
      "Current step: 600\n",
      "Test loss and acc: 0.7086 0.8077\n",
      "Training loss and acc: 0.2416 0.8881\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7370 - accuracy: 0.7874\n",
      "Current step: 650\n",
      "Test loss and acc: 0.7370 0.7874\n",
      "Training loss and acc: 0.2536 0.8882\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7693 - accuracy: 0.7893\n",
      "Current step: 700\n",
      "Test loss and acc: 0.7693 0.7893\n",
      "Training loss and acc: 0.1851 0.8885\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7434 - accuracy: 0.7986\n",
      "Current step: 750\n",
      "Test loss and acc: 0.7434 0.7986\n",
      "Training loss and acc: 0.2286 0.8888\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7623 - accuracy: 0.8001\n",
      "Current step: 800\n",
      "Test loss and acc: 0.7623 0.8001\n",
      "Training loss and acc: 0.2826 0.8886\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.6755 - accuracy: 0.7990\n",
      "Current step: 850\n",
      "Test loss and acc: 0.6755 0.7990\n",
      "Training loss and acc: 0.3376 0.8888\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 44ms/step - loss: 0.7600 - accuracy: 0.7723\n",
      "Current step: 900\n",
      "Test loss and acc: 0.7600 0.7723\n",
      "Training loss and acc: 0.3452 0.8892\n",
      "Seen so far: 57664 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        # Log every 50 batches.\n",
    "        if step % 50 == 0 and step > 0:\n",
    "            test_loss_acc = model.evaluate(X_test, Y_test, batch_size=64)\n",
    "            train_loss_acc = float(loss_value), float(train_acc_metric.result()) \n",
    "            test_loss.append(test_loss_acc[0])\n",
    "            test_acc.append(test_loss_acc[1])\n",
    "            train_loss.append(train_loss_acc[0])\n",
    "            train_acc.append(train_loss_acc[1])\n",
    "            print(\"Current step: %d\" % step)\n",
    "            print(\"Test loss and acc: %.4f %.4f\" % (test_loss_acc[0], test_loss_acc[1]))\n",
    "            print(\"Training loss and acc: %.4f %.4f\" % (float(train_loss_acc[0]), float(train_loss_acc[1])))\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7180 - accuracy: 0.7984\n",
      "Current step: 50\n",
      "Test loss and acc: 0.7180 0.7984\n",
      "Training loss and acc: 0.3736 0.9056\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8028 - accuracy: 0.7867\n",
      "Current step: 100\n",
      "Test loss and acc: 0.8028 0.7867\n",
      "Training loss and acc: 0.4694 0.9083\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.7168 - accuracy: 0.8014\n",
      "Current step: 150\n",
      "Test loss and acc: 0.7168 0.8014\n",
      "Training loss and acc: 0.2807 0.9087\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7518 - accuracy: 0.8021\n",
      "Current step: 200\n",
      "Test loss and acc: 0.7518 0.8021\n",
      "Training loss and acc: 0.1394 0.9106\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.7628 - accuracy: 0.7922\n",
      "Current step: 250\n",
      "Test loss and acc: 0.7628 0.7922\n",
      "Training loss and acc: 0.2858 0.9090\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.6783 - accuracy: 0.8049\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6783 0.8049\n",
      "Training loss and acc: 0.2896 0.9065\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7555 - accuracy: 0.8069\n",
      "Current step: 350\n",
      "Test loss and acc: 0.7555 0.8069\n",
      "Training loss and acc: 0.2718 0.9081\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7397 - accuracy: 0.7972\n",
      "Current step: 400\n",
      "Test loss and acc: 0.7397 0.7972\n",
      "Training loss and acc: 0.4045 0.9089\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7452 - accuracy: 0.7994\n",
      "Current step: 450\n",
      "Test loss and acc: 0.7452 0.7994\n",
      "Training loss and acc: 0.2422 0.9086\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.7500 - accuracy: 0.8004\n",
      "Current step: 500\n",
      "Test loss and acc: 0.7500 0.8004\n",
      "Training loss and acc: 0.1700 0.9098\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7699 - accuracy: 0.8041\n",
      "Current step: 550\n",
      "Test loss and acc: 0.7699 0.8041\n",
      "Training loss and acc: 0.3609 0.9100\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8082 - accuracy: 0.7998\n",
      "Current step: 600\n",
      "Test loss and acc: 0.8082 0.7998\n",
      "Training loss and acc: 0.1138 0.9111\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8008 - accuracy: 0.7854\n",
      "Current step: 650\n",
      "Test loss and acc: 0.8008 0.7854\n",
      "Training loss and acc: 0.1818 0.9119\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8500 - accuracy: 0.7882\n",
      "Current step: 700\n",
      "Test loss and acc: 0.8500 0.7882\n",
      "Training loss and acc: 0.1318 0.9116\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.9371 - accuracy: 0.7840\n",
      "Current step: 750\n",
      "Test loss and acc: 0.9371 0.7840\n",
      "Training loss and acc: 0.2288 0.9120\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8120 - accuracy: 0.8024\n",
      "Current step: 800\n",
      "Test loss and acc: 0.8120 0.8024\n",
      "Training loss and acc: 0.2242 0.9124\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7637 - accuracy: 0.8074\n",
      "Current step: 850\n",
      "Test loss and acc: 0.7637 0.8074\n",
      "Training loss and acc: 0.2528 0.9122\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8439 - accuracy: 0.7710\n",
      "Current step: 900\n",
      "Test loss and acc: 0.8439 0.7710\n",
      "Training loss and acc: 0.3000 0.9123\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 1\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8214 - accuracy: 0.7919\n",
      "Current step: 50\n",
      "Test loss and acc: 0.8214 0.7919\n",
      "Training loss and acc: 0.2708 0.9256\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8919 - accuracy: 0.7884\n",
      "Current step: 100\n",
      "Test loss and acc: 0.8919 0.7884\n",
      "Training loss and acc: 0.2531 0.9322\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.7802 - accuracy: 0.7919\n",
      "Current step: 150\n",
      "Test loss and acc: 0.7802 0.7919\n",
      "Training loss and acc: 0.2032 0.9266\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8430 - accuracy: 0.7950\n",
      "Current step: 200\n",
      "Test loss and acc: 0.8430 0.7950\n",
      "Training loss and acc: 0.1783 0.9299\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8357 - accuracy: 0.7860\n",
      "Current step: 250\n",
      "Test loss and acc: 0.8357 0.7860\n",
      "Training loss and acc: 0.2198 0.9280\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7756 - accuracy: 0.8001\n",
      "Current step: 300\n",
      "Test loss and acc: 0.7756 0.8001\n",
      "Training loss and acc: 0.2212 0.9260\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.9652 - accuracy: 0.7925\n",
      "Current step: 350\n",
      "Test loss and acc: 0.9652 0.7925\n",
      "Training loss and acc: 0.2168 0.9271\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.7994 - accuracy: 0.7998\n",
      "Current step: 400\n",
      "Test loss and acc: 0.7994 0.7998\n",
      "Training loss and acc: 0.2582 0.9271\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8209 - accuracy: 0.8026\n",
      "Current step: 450\n",
      "Test loss and acc: 0.8209 0.8026\n",
      "Training loss and acc: 0.1805 0.9270\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 5s 46ms/step - loss: 0.8089 - accuracy: 0.8026\n",
      "Current step: 500\n",
      "Test loss and acc: 0.8089 0.8026\n",
      "Training loss and acc: 0.1321 0.9273\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8353 - accuracy: 0.8006\n",
      "Current step: 550\n",
      "Test loss and acc: 0.8353 0.8006\n",
      "Training loss and acc: 0.3248 0.9272\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 5s 45ms/step - loss: 0.8545 - accuracy: 0.8043\n",
      "Current step: 600\n",
      "Test loss and acc: 0.8545 0.8043\n",
      "Training loss and acc: 0.1480 0.9282\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 5s 49ms/step - loss: 0.8891 - accuracy: 0.7845\n",
      "Current step: 650\n",
      "Test loss and acc: 0.8891 0.7845\n",
      "Training loss and acc: 0.2006 0.9284\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 5s 47ms/step - loss: 0.8327 - accuracy: 0.7833\n",
      "Current step: 700\n",
      "Test loss and acc: 0.8327 0.7833\n",
      "Training loss and acc: 0.0864 0.9284\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8002 - accuracy: 0.8058\n",
      "Current step: 750\n",
      "Test loss and acc: 0.8002 0.8058\n",
      "Training loss and acc: 0.1924 0.9282\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 5s 48ms/step - loss: 0.8548 - accuracy: 0.7955\n",
      "Current step: 800\n",
      "Test loss and acc: 0.8548 0.7955\n",
      "Training loss and acc: 0.1326 0.9286\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8318 - accuracy: 0.7952\n",
      "Current step: 850\n",
      "Test loss and acc: 0.8318 0.7952\n",
      "Training loss and acc: 0.2183 0.9285\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 43ms/step - loss: 0.8991 - accuracy: 0.7727\n",
      "Current step: 900\n",
      "Test loss and acc: 0.8991 0.7727\n",
      "Training loss and acc: 0.1795 0.9290\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 2\n",
      "101/101 [==============================] - 4s 44ms/step - loss: 0.8548 - accuracy: 0.8009\n",
      "Current step: 50\n",
      "Test loss and acc: 0.8548 0.8009\n",
      "Training loss and acc: 0.1667 0.9347\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 5s 47ms/step - loss: 1.0132 - accuracy: 0.7653\n",
      "Current step: 100\n",
      "Test loss and acc: 1.0132 0.7653\n",
      "Training loss and acc: 0.1848 0.9380\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8377 - accuracy: 0.7936\n",
      "Current step: 150\n",
      "Test loss and acc: 0.8377 0.7936\n",
      "Training loss and acc: 0.3799 0.9373\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 44ms/step - loss: 0.9316 - accuracy: 0.7802\n",
      "Current step: 200\n",
      "Test loss and acc: 0.9316 0.7802\n",
      "Training loss and acc: 0.1904 0.9373\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 5s 46ms/step - loss: 0.8313 - accuracy: 0.8043\n",
      "Current step: 250\n",
      "Test loss and acc: 0.8313 0.8043\n",
      "Training loss and acc: 0.0760 0.9377\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8961 - accuracy: 0.7941\n",
      "Current step: 300\n",
      "Test loss and acc: 0.8961 0.7941\n",
      "Training loss and acc: 0.1940 0.9363\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.8752 - accuracy: 0.8075\n",
      "Current step: 350\n",
      "Test loss and acc: 0.8752 0.8075\n",
      "Training loss and acc: 0.0719 0.9370\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.9201 - accuracy: 0.7842\n",
      "Current step: 400\n",
      "Test loss and acc: 0.9201 0.7842\n",
      "Training loss and acc: 0.1843 0.9364\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 44ms/step - loss: 0.9585 - accuracy: 0.7998\n",
      "Current step: 450\n",
      "Test loss and acc: 0.9585 0.7998\n",
      "Training loss and acc: 0.1500 0.9374\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 5s 50ms/step - loss: 0.8814 - accuracy: 0.8007\n",
      "Current step: 500\n",
      "Test loss and acc: 0.8814 0.8007\n",
      "Training loss and acc: 0.1454 0.9385\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 5s 46ms/step - loss: 0.8891 - accuracy: 0.8000\n",
      "Current step: 550\n",
      "Test loss and acc: 0.8891 0.8000\n",
      "Training loss and acc: 0.2994 0.9380\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 5s 47ms/step - loss: 0.9246 - accuracy: 0.8004\n",
      "Current step: 600\n",
      "Test loss and acc: 0.9246 0.8004\n",
      "Training loss and acc: 0.1222 0.9385\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8641 - accuracy: 0.8007\n",
      "Current step: 650\n",
      "Test loss and acc: 0.8641 0.8007\n",
      "Training loss and acc: 0.0825 0.9391\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.9097 - accuracy: 0.7817\n",
      "Current step: 700\n",
      "Test loss and acc: 0.9097 0.7817\n",
      "Training loss and acc: 0.2156 0.9395\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 5s 47ms/step - loss: 0.9403 - accuracy: 0.7953\n",
      "Current step: 750\n",
      "Test loss and acc: 0.9403 0.7953\n",
      "Training loss and acc: 0.0535 0.9395\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.9345 - accuracy: 0.8006\n",
      "Current step: 800\n",
      "Test loss and acc: 0.9345 0.8006\n",
      "Training loss and acc: 0.0578 0.9400\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.9752 - accuracy: 0.7740\n",
      "Current step: 850\n",
      "Test loss and acc: 0.9752 0.7740\n",
      "Training loss and acc: 0.2378 0.9399\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.8695 - accuracy: 0.7901\n",
      "Current step: 900\n",
      "Test loss and acc: 0.8695 0.7901\n",
      "Training loss and acc: 0.1736 0.9401\n",
      "Seen so far: 57664 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        # Log every 50 batches.\n",
    "        if step % 50 == 0 and step > 0:\n",
    "            test_loss_acc = model.evaluate(X_test, Y_test, batch_size=64)\n",
    "            train_loss_acc = float(loss_value), float(train_acc_metric.result()) \n",
    "            test_loss.append(test_loss_acc[0])\n",
    "            test_acc.append(test_loss_acc[1])\n",
    "            train_loss.append(train_loss_acc[0])\n",
    "            train_acc.append(train_loss_acc[1])\n",
    "            print(\"Current step: %d\" % step)\n",
    "            print(\"Test loss and acc: %.4f %.4f\" % (test_loss_acc[0], test_loss_acc[1]))\n",
    "            print(\"Training loss and acc: %.4f %.4f\" % (float(train_loss_acc[0]), float(train_loss_acc[1])))\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Mi Notebook\\Desktop\\Audio_project\\audio_project\\Spotter_recognition\\saved_models\\CRNN\\assets\n",
      "Save model and weights at C:\\Users\\Mi Notebook\\Desktop\\Audio_project\\audio_project\\Spotter_recognition\\saved_models\\CRNN \n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"CRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_history(model_history.history, \"CRNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.arange(50, 8150, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "train_plot = plt.plot(temp, train_loss, color='red', label='Train')\n",
    "test_plot = plt.plot(temp, test_loss, color='black', linestyle='dashed', label='Test')\n",
    "plt.title('CRNN loss')\n",
    "plt.ylabel('CategoricalCrossentropy loss')\n",
    "plt.xlabel('batch \\n (3 epoch)')\n",
    "plt.legend(loc='upper right')\n",
    "#plt.savefig(\"CRNN_withou_spec_auc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.87      0.78      0.82       254\n",
      "          go       0.93      0.83      0.88       229\n",
      "        left       0.90      0.81      0.86       236\n",
      "          no       0.87      0.75      0.81       242\n",
      "         off       0.86      0.80      0.83       226\n",
      "          on       0.83      0.77      0.80       229\n",
      "       right       0.89      0.81      0.85       252\n",
      "        stop       0.95      0.84      0.89       235\n",
      "     unknown       0.92      0.97      0.95      4081\n",
      "          up       0.89      0.78      0.84       250\n",
      "         yes       0.98      0.89      0.93       239\n",
      "\n",
      "    accuracy                           0.91      6473\n",
      "   macro avg       0.90      0.82      0.86      6473\n",
      "weighted avg       0.91      0.91      0.91      6473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report(model, X_test, Y_test, lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
