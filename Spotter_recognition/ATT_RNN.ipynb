{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, TimeDistributed, Bidirectional\n",
    "from keras.layers import Dot, Softmax\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, MaxPool2D\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.read_csv(os.path.abspath('Target_words_dataframe'))\n",
    "df_unknown = pd.read_csv(os.path.abspath('Unknown_words_dataframe'))\n",
    "df = pd.read_csv(os.path.abspath('full_df'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.drop(columns=['Unnamed: 0'], axis=1)\n",
    "df_unknown = df_unknown.drop(columns=['Unnamed: 0'], axis=1)\n",
    "df = df.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.abspath('../../Data_spotter_mfcc_40')\n",
    "outfile = open(filename,'rb')\n",
    "X = pickle.load(outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(Model, model_name):\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    Model.save(model_path)\n",
    "    print('Save model and weights at %s ' % model_path)\n",
    "\n",
    "    model_json = Model.to_json()\n",
    "    with open(\"model_json.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_history(model_history, model_history_name):\n",
    "    filename = 'saved_models_history/' + model_history_name\n",
    "    outfile = open(filename,'wb')\n",
    "    pickle.dump(model_history, outfile)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model, X, y, classes):\n",
    "    model_predictions = model.predict(X).argmax(axis=1)\n",
    "    true_predictions = y.argmax(axis=1)\n",
    "    return sklearn.metrics.classification_report(true_predictions, model_predictions, target_names=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X\n",
    "                                                    , df.word\n",
    "                                                    , test_size=6464\n",
    "                                                    , train_size = 58240\n",
    "                                                    , shuffle=True\n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size = (58240, 40, 61)\n",
      "Y_train size = (58240,)\n",
      "X_test size = (6464, 40, 61)\n",
      "Y_test size = (6464,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train size = {X_train.shape}')\n",
    "print(f'Y_train size = {Y_train.shape}')\n",
    "print(f'X_test size = {X_test.shape}')\n",
    "print(f'Y_test size = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'stop' 'unkown' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "lb = LabelEncoder()\n",
    "Y_train = np_utils.to_categorical(lb.fit_transform(Y_train))\n",
    "Y_test = np_utils.to_categorical(lb.fit_transform(Y_test))\n",
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size = (58240, 40, 61, 1)\n",
      "X_test size = (6464, 40, 61, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "print(f'X_train size = {X_train.shape}')\n",
    "print(f'X_test size = {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATT_RNN_model(input_shape, nclass):\n",
    "    \n",
    "    input_ = Input(input_shape)\n",
    "    \n",
    "    X = Convolution2D(10, (5, 1), activation=\"relu\", dilation_rate=(1, 1), strides=(1, 1))(input_)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Convolution2D(1, (5, 1), activation=\"relu\", dilation_rate=(1, 1), strides=(1, 1))(X)\n",
    "    X = BatchNormalization()(X)\n",
    "    shape = X.shape\n",
    "    X = tf.keras.layers.Reshape((-1, shape[2] * shape[3]))(X)\n",
    "    X = Bidirectional(GRU(units=128,  return_sequences=True, unroll=True))(X)\n",
    "    X = Bidirectional(GRU(units=128,  return_sequences=True, unroll=True))(X)\n",
    "    \n",
    "    feature_dim = X.shape[-1]\n",
    "    middle = X.shape[1] // 2\n",
    "    mid_feature = X[:, middle, :]\n",
    "    \n",
    "    query = Dense(feature_dim)(mid_feature)\n",
    "        \n",
    "    att_weights = Dot(axes=[1, 2])([query, X])\n",
    "    att_weights = Softmax(name='attSoftmax')(att_weights)\n",
    "    X = Dot(axes=[1, 1])([att_weights, X])\n",
    "    X = Dropout(rate=0.1)(X)\n",
    "    \n",
    "    X = Dense(64, activation=\"relu\")(X)\n",
    "    X = Dense(32, activation=\"linear\")(X)\n",
    "    \n",
    "    output_ = Dense(nclass, activation='softmax')(X)\n",
    "    \n",
    "    ret_model = Model(inputs = input_, outputs=output_)\n",
    "    \n",
    "    return ret_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ATT_RNN_model((40, 61, 1), len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 40, 61, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 36, 61, 10)   60          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 36, 61, 10)   40          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 61, 1)    51          batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 61, 1)    4           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 61)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 32, 256)      146688      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32, 256)      296448      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          65792       tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 32)           0           dense[0][0]                      \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attSoftmax (Softmax)            (None, 32)           0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 256)          0           attSoftmax[0][0]                 \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           363         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 527,974\n",
      "Trainable params: 527,952\n",
      "Non-trainable params: 22\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(0.001)\n",
    "model.compile(optimizer = opt, loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "loss_fn = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "train_acc_metric = keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "101/101 [==============================] - 7s 34ms/step - loss: 1.5861 - accuracy: 0.6425\n",
      "Current step: 50\n",
      "Test loss and acc: 1.6100 0.6303\n",
      "Training loss and acc: 1.7239 0.6127\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 1.5063 - accuracy: 0.6303\n",
      "Current step: 100\n",
      "Test loss and acc: 1.5063 0.6303\n",
      "Training loss and acc: 1.2790 0.6282\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 1.5606 - accuracy: 0.6304\n",
      "Current step: 150\n",
      "Test loss and acc: 1.5606 0.6304\n",
      "Training loss and acc: 1.3647 0.6327\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 1.4008 - accuracy: 0.6301\n",
      "Current step: 200\n",
      "Test loss and acc: 1.4008 0.6301\n",
      "Training loss and acc: 1.1967 0.6301\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 37ms/step - loss: 1.3460 - accuracy: 0.6341\n",
      "Current step: 250\n",
      "Test loss and acc: 1.3460 0.6341\n",
      "Training loss and acc: 1.5605 0.6304\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 1.2751 - accuracy: 0.6363\n",
      "Current step: 300\n",
      "Test loss and acc: 1.2751 0.6363\n",
      "Training loss and acc: 1.1928 0.6324\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 1.2195 - accuracy: 0.6437\n",
      "Current step: 350\n",
      "Test loss and acc: 1.2195 0.6437\n",
      "Training loss and acc: 1.3060 0.6345\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 1.1969 - accuracy: 0.6481\n",
      "Current step: 400\n",
      "Test loss and acc: 1.1969 0.6481\n",
      "Training loss and acc: 1.0405 0.6371\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 1.1706 - accuracy: 0.6494\n",
      "Current step: 450\n",
      "Test loss and acc: 1.1706 0.6494\n",
      "Training loss and acc: 1.3340 0.6399\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 1.1167 - accuracy: 0.6609\n",
      "Current step: 500\n",
      "Test loss and acc: 1.1167 0.6609\n",
      "Training loss and acc: 1.1059 0.6424\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 1.0958 - accuracy: 0.6610\n",
      "Current step: 550\n",
      "Test loss and acc: 1.0958 0.6610\n",
      "Training loss and acc: 1.1665 0.6442\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 1.0677 - accuracy: 0.6703\n",
      "Current step: 600\n",
      "Test loss and acc: 1.0677 0.6703\n",
      "Training loss and acc: 1.0907 0.6465\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 1.0507 - accuracy: 0.6773\n",
      "Current step: 650\n",
      "Test loss and acc: 1.0507 0.6773\n",
      "Training loss and acc: 0.9893 0.6478\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 1.0178 - accuracy: 0.6793\n",
      "Current step: 700\n",
      "Test loss and acc: 1.0178 0.6793\n",
      "Training loss and acc: 1.0536 0.6496\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 3s 33ms/step - loss: 1.0412 - accuracy: 0.6716\n",
      "Current step: 750\n",
      "Test loss and acc: 1.0412 0.6716\n",
      "Training loss and acc: 0.8677 0.6523\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.9901 - accuracy: 0.6875\n",
      "Current step: 800\n",
      "Test loss and acc: 0.9901 0.6875\n",
      "Training loss and acc: 1.0607 0.6540\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.9910 - accuracy: 0.6853\n",
      "Current step: 850\n",
      "Test loss and acc: 0.9910 0.6853\n",
      "Training loss and acc: 0.9940 0.6556\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 0.9340 - accuracy: 0.6974\n",
      "Current step: 900\n",
      "Test loss and acc: 0.9340 0.6974\n",
      "Training loss and acc: 0.8800 0.6578\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 1\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.9220 - accuracy: 0.7024\n",
      "Current step: 50\n",
      "Test loss and acc: 0.9220 0.7024\n",
      "Training loss and acc: 1.0583 0.7154\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 0.9072 - accuracy: 0.7095\n",
      "Current step: 100\n",
      "Test loss and acc: 0.9072 0.7095\n",
      "Training loss and acc: 0.8121 0.7132\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.9091 - accuracy: 0.7039\n",
      "Current step: 150\n",
      "Test loss and acc: 0.9091 0.7039\n",
      "Training loss and acc: 0.9526 0.7119\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.8767 - accuracy: 0.7163\n",
      "Current step: 200\n",
      "Test loss and acc: 0.8767 0.7163\n",
      "Training loss and acc: 0.7443 0.7087\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.8651 - accuracy: 0.7205\n",
      "Current step: 250\n",
      "Test loss and acc: 0.8651 0.7205\n",
      "Training loss and acc: 0.8477 0.7123\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 3s 33ms/step - loss: 0.8433 - accuracy: 0.7206\n",
      "Current step: 300\n",
      "Test loss and acc: 0.8433 0.7206\n",
      "Training loss and acc: 0.7686 0.7116\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.8191 - accuracy: 0.7328\n",
      "Current step: 350\n",
      "Test loss and acc: 0.8191 0.7328\n",
      "Training loss and acc: 0.7715 0.7133\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 3s 33ms/step - loss: 0.8185 - accuracy: 0.7350\n",
      "Current step: 400\n",
      "Test loss and acc: 0.8185 0.7350\n",
      "Training loss and acc: 0.8528 0.7169\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 3s 33ms/step - loss: 0.7895 - accuracy: 0.7396\n",
      "Current step: 450\n",
      "Test loss and acc: 0.7895 0.7396\n",
      "Training loss and acc: 0.9539 0.7206\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.7863 - accuracy: 0.7427\n",
      "Current step: 500\n",
      "Test loss and acc: 0.7863 0.7427\n",
      "Training loss and acc: 0.7442 0.7223\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 37ms/step - loss: 0.8092 - accuracy: 0.7392\n",
      "Current step: 550\n",
      "Test loss and acc: 0.8092 0.7392\n",
      "Training loss and acc: 0.7943 0.7247\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.7552 - accuracy: 0.7517\n",
      "Current step: 600\n",
      "Test loss and acc: 0.7552 0.7517\n",
      "Training loss and acc: 0.5762 0.7282\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.7659 - accuracy: 0.7455\n",
      "Current step: 650\n",
      "Test loss and acc: 0.7659 0.7455\n",
      "Training loss and acc: 0.6798 0.7297\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.7805 - accuracy: 0.7441\n",
      "Current step: 700\n",
      "Test loss and acc: 0.7805 0.7441\n",
      "Training loss and acc: 1.0147 0.7318\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.7466 - accuracy: 0.7551\n",
      "Current step: 750\n",
      "Test loss and acc: 0.7466 0.7551\n",
      "Training loss and acc: 0.5881 0.7330\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.7275 - accuracy: 0.7633\n",
      "Current step: 800\n",
      "Test loss and acc: 0.7275 0.7633\n",
      "Training loss and acc: 0.7195 0.7350\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.7196 - accuracy: 0.7590\n",
      "Current step: 850\n",
      "Test loss and acc: 0.7196 0.7590\n",
      "Training loss and acc: 0.6992 0.7367\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6971 - accuracy: 0.7687\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6971 0.7687\n",
      "Training loss and acc: 0.5980 0.7385\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 2\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.7078 - accuracy: 0.7672\n",
      "Current step: 50\n",
      "Test loss and acc: 0.7078 0.7672\n",
      "Training loss and acc: 0.7948 0.7816\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.7043 - accuracy: 0.7678\n",
      "Current step: 100\n",
      "Test loss and acc: 0.7043 0.7678\n",
      "Training loss and acc: 0.6216 0.7819\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.7038 - accuracy: 0.7712\n",
      "Current step: 150\n",
      "Test loss and acc: 0.7038 0.7712\n",
      "Training loss and acc: 0.7422 0.7824\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 0.7031 - accuracy: 0.7666\n",
      "Current step: 200\n",
      "Test loss and acc: 0.7031 0.7666\n",
      "Training loss and acc: 0.3851 0.7829\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 3s 35ms/step - loss: 0.6590 - accuracy: 0.7822\n",
      "Current step: 250\n",
      "Test loss and acc: 0.6590 0.7822\n",
      "Training loss and acc: 0.6967 0.7842\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6746 - accuracy: 0.7777\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6746 0.7777\n",
      "Training loss and acc: 0.6022 0.7845\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6476 - accuracy: 0.7893\n",
      "Current step: 350\n",
      "Test loss and acc: 0.6476 0.7893\n",
      "Training loss and acc: 0.4960 0.7867\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6727 - accuracy: 0.7799\n",
      "Current step: 400\n",
      "Test loss and acc: 0.6727 0.7799\n",
      "Training loss and acc: 0.7539 0.7891\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6394 - accuracy: 0.7913\n",
      "Current step: 450\n",
      "Test loss and acc: 0.6394 0.7913\n",
      "Training loss and acc: 0.4561 0.7917\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6680 - accuracy: 0.7795\n",
      "Current step: 500\n",
      "Test loss and acc: 0.6680 0.7795\n",
      "Training loss and acc: 0.4945 0.7925\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6620 - accuracy: 0.7834\n",
      "Current step: 550\n",
      "Test loss and acc: 0.6620 0.7834\n",
      "Training loss and acc: 0.7692 0.7949\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 3s 33ms/step - loss: 0.6338 - accuracy: 0.7924\n",
      "Current step: 600\n",
      "Test loss and acc: 0.6338 0.7924\n",
      "Training loss and acc: 0.4932 0.7973\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6294 - accuracy: 0.7896\n",
      "Current step: 650\n",
      "Test loss and acc: 0.6294 0.7896\n",
      "Training loss and acc: 0.4624 0.7979\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6609 - accuracy: 0.7850\n",
      "Current step: 700\n",
      "Test loss and acc: 0.6609 0.7850\n",
      "Training loss and acc: 0.7152 0.7989\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6253 - accuracy: 0.7938\n",
      "Current step: 750\n",
      "Test loss and acc: 0.6253 0.7938\n",
      "Training loss and acc: 0.4269 0.7995\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 35ms/step - loss: 0.6379 - accuracy: 0.7924\n",
      "Current step: 800\n",
      "Test loss and acc: 0.6379 0.7924\n",
      "Training loss and acc: 0.5107 0.8000\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 36ms/step - loss: 0.6148 - accuracy: 0.7924\n",
      "Current step: 850\n",
      "Test loss and acc: 0.6148 0.7924\n",
      "Training loss and acc: 0.4988 0.8012\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 3s 34ms/step - loss: 0.6226 - accuracy: 0.7879\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6226 0.7879\n",
      "Training loss and acc: 0.4961 0.8020\n",
      "Seen so far: 57664 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        # Log every 50 batches.\n",
    "        if step % 50 == 0 and step > 0:\n",
    "            test_loss_acc = model.evaluate(X_test, Y_test, batch_size=64)\n",
    "            train_loss_acc = float(loss_value), float(train_acc_metric.result()) \n",
    "            test_loss.append(test_loss_acc[0])\n",
    "            test_acc.append(test_loss_acc[1])\n",
    "            train_loss.append(train_loss_acc[0])\n",
    "            train_acc.append(train_loss_acc[1])\n",
    "            print(\"Current step: %d\" % step)\n",
    "            print(\"Test loss and acc: %.4f %.4f\" % (test_loss_acc[0], test_loss_acc[1]))\n",
    "            print(\"Training loss and acc: %.4f %.4f\" % (float(train_loss_acc[0]), float(train_loss_acc[1])))\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6128 - accuracy: 0.8009\n",
      "Current step: 50\n",
      "Test loss and acc: 0.6128 0.8009\n",
      "Training loss and acc: 0.6589 0.8220\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6059 - accuracy: 0.8021\n",
      "Current step: 100\n",
      "Test loss and acc: 0.6059 0.8021\n",
      "Training loss and acc: 0.4577 0.8326\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.6080 - accuracy: 0.8017\n",
      "Current step: 150\n",
      "Test loss and acc: 0.6080 0.8017\n",
      "Training loss and acc: 0.5867 0.8276\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6149 - accuracy: 0.8024\n",
      "Current step: 200\n",
      "Test loss and acc: 0.6149 0.8024\n",
      "Training loss and acc: 0.3336 0.8282\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.5887 - accuracy: 0.8091\n",
      "Current step: 250\n",
      "Test loss and acc: 0.5887 0.8091\n",
      "Training loss and acc: 0.6679 0.8292\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.6082 - accuracy: 0.7966\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6082 0.7966\n",
      "Training loss and acc: 0.4706 0.8296\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 42ms/step - loss: 0.5843 - accuracy: 0.8108\n",
      "Current step: 350\n",
      "Test loss and acc: 0.5843 0.8108\n",
      "Training loss and acc: 0.3876 0.8310\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.6174 - accuracy: 0.7989\n",
      "Current step: 400\n",
      "Test loss and acc: 0.6174 0.7989\n",
      "Training loss and acc: 0.6023 0.8324\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.5870 - accuracy: 0.8080\n",
      "Current step: 450\n",
      "Test loss and acc: 0.5870 0.8080\n",
      "Training loss and acc: 0.3478 0.8338\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.5864 - accuracy: 0.8096\n",
      "Current step: 500\n",
      "Test loss and acc: 0.5864 0.8096\n",
      "Training loss and acc: 0.3230 0.8341\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.6368 - accuracy: 0.7963\n",
      "Current step: 550\n",
      "Test loss and acc: 0.6368 0.7963\n",
      "Training loss and acc: 0.5584 0.8358\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.5880 - accuracy: 0.8093\n",
      "Current step: 600\n",
      "Test loss and acc: 0.5880 0.8093\n",
      "Training loss and acc: 0.4064 0.8370\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.6064 - accuracy: 0.7983\n",
      "Current step: 650\n",
      "Test loss and acc: 0.6064 0.7983\n",
      "Training loss and acc: 0.3428 0.8379\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.6204 - accuracy: 0.8017\n",
      "Current step: 700\n",
      "Test loss and acc: 0.6204 0.8017\n",
      "Training loss and acc: 0.4164 0.8386\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.5848 - accuracy: 0.8111\n",
      "Current step: 750\n",
      "Test loss and acc: 0.5848 0.8111\n",
      "Training loss and acc: 0.4406 0.8391\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6127 - accuracy: 0.8045\n",
      "Current step: 800\n",
      "Test loss and acc: 0.6127 0.8045\n",
      "Training loss and acc: 0.4536 0.8397\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5757 - accuracy: 0.8072\n",
      "Current step: 850\n",
      "Test loss and acc: 0.5757 0.8072\n",
      "Training loss and acc: 0.3701 0.8403\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.6151 - accuracy: 0.8003\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6151 0.8003\n",
      "Training loss and acc: 0.3652 0.8409\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 1\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5805 - accuracy: 0.8102\n",
      "Current step: 50\n",
      "Test loss and acc: 0.5805 0.8102\n",
      "Training loss and acc: 0.5556 0.8600\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5914 - accuracy: 0.8093\n",
      "Current step: 100\n",
      "Test loss and acc: 0.5914 0.8093\n",
      "Training loss and acc: 0.3905 0.8603\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5840 - accuracy: 0.8111\n",
      "Current step: 150\n",
      "Test loss and acc: 0.5840 0.8111\n",
      "Training loss and acc: 0.5304 0.8603\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.5859 - accuracy: 0.8106\n",
      "Current step: 200\n",
      "Test loss and acc: 0.5859 0.8106\n",
      "Training loss and acc: 0.2190 0.8616\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5670 - accuracy: 0.8178\n",
      "Current step: 250\n",
      "Test loss and acc: 0.5670 0.8178\n",
      "Training loss and acc: 0.5377 0.8617\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.6006 - accuracy: 0.8086\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6006 0.8086\n",
      "Training loss and acc: 0.3450 0.8620\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5744 - accuracy: 0.8182\n",
      "Current step: 350\n",
      "Test loss and acc: 0.5744 0.8182\n",
      "Training loss and acc: 0.3325 0.8617\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.5804 - accuracy: 0.8170\n",
      "Current step: 400\n",
      "Test loss and acc: 0.5804 0.8170\n",
      "Training loss and acc: 0.5659 0.8626\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.5773 - accuracy: 0.8238\n",
      "Current step: 450\n",
      "Test loss and acc: 0.5773 0.8238\n",
      "Training loss and acc: 0.2800 0.8633\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.5799 - accuracy: 0.8131\n",
      "Current step: 500\n",
      "Test loss and acc: 0.5799 0.8131\n",
      "Training loss and acc: 0.2421 0.8639\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6257 - accuracy: 0.8031\n",
      "Current step: 550\n",
      "Test loss and acc: 0.6257 0.8031\n",
      "Training loss and acc: 0.4024 0.8660\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.6093 - accuracy: 0.8117\n",
      "Current step: 600\n",
      "Test loss and acc: 0.6093 0.8117\n",
      "Training loss and acc: 0.2309 0.8674\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.5991 - accuracy: 0.8094\n",
      "Current step: 650\n",
      "Test loss and acc: 0.5991 0.8094\n",
      "Training loss and acc: 0.2543 0.8675\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6072 - accuracy: 0.8117\n",
      "Current step: 700\n",
      "Test loss and acc: 0.6072 0.8117\n",
      "Training loss and acc: 0.3363 0.8678\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.5918 - accuracy: 0.8113\n",
      "Current step: 750\n",
      "Test loss and acc: 0.5918 0.8113\n",
      "Training loss and acc: 0.3414 0.8679\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 37ms/step - loss: 0.6153 - accuracy: 0.8105\n",
      "Current step: 800\n",
      "Test loss and acc: 0.6153 0.8105\n",
      "Training loss and acc: 0.4095 0.8681\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 37ms/step - loss: 0.5753 - accuracy: 0.8192\n",
      "Current step: 850\n",
      "Test loss and acc: 0.5753 0.8192\n",
      "Training loss and acc: 0.2612 0.8683\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 37ms/step - loss: 0.6445 - accuracy: 0.7969\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6445 0.7969\n",
      "Training loss and acc: 0.3173 0.8684\n",
      "Seen so far: 57664 samples\n",
      "\n",
      "Start of epoch 2\n",
      "101/101 [==============================] - 4s 41ms/step - loss: 0.6121 - accuracy: 0.8102\n",
      "Current step: 50\n",
      "Test loss and acc: 0.6121 0.8102\n",
      "Training loss and acc: 0.4715 0.8790\n",
      "Seen so far: 3264 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5941 - accuracy: 0.8136\n",
      "Current step: 100\n",
      "Test loss and acc: 0.5941 0.8136\n",
      "Training loss and acc: 0.3208 0.8795\n",
      "Seen so far: 6464 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.5892 - accuracy: 0.8157\n",
      "Current step: 150\n",
      "Test loss and acc: 0.5892 0.8157\n",
      "Training loss and acc: 0.3970 0.8807\n",
      "Seen so far: 9664 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5797 - accuracy: 0.8261\n",
      "Current step: 200\n",
      "Test loss and acc: 0.5797 0.8261\n",
      "Training loss and acc: 0.2408 0.8808\n",
      "Seen so far: 12864 samples\n",
      "101/101 [==============================] - 4s 40ms/step - loss: 0.5920 - accuracy: 0.8192\n",
      "Current step: 250\n",
      "Test loss and acc: 0.5920 0.8192\n",
      "Training loss and acc: 0.4909 0.8815\n",
      "Seen so far: 16064 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.6332 - accuracy: 0.8079\n",
      "Current step: 300\n",
      "Test loss and acc: 0.6332 0.8079\n",
      "Training loss and acc: 0.3088 0.8807\n",
      "Seen so far: 19264 samples\n",
      "101/101 [==============================] - 4s 37ms/step - loss: 0.6015 - accuracy: 0.8218\n",
      "Current step: 350\n",
      "Test loss and acc: 0.6015 0.8218\n",
      "Training loss and acc: 0.2755 0.8805\n",
      "Seen so far: 22464 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.5894 - accuracy: 0.8179\n",
      "Current step: 400\n",
      "Test loss and acc: 0.5894 0.8179\n",
      "Training loss and acc: 0.4380 0.8821\n",
      "Seen so far: 25664 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6019 - accuracy: 0.8252\n",
      "Current step: 450\n",
      "Test loss and acc: 0.6019 0.8252\n",
      "Training loss and acc: 0.1919 0.8831\n",
      "Seen so far: 28864 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6071 - accuracy: 0.8210\n",
      "Current step: 500\n",
      "Test loss and acc: 0.6071 0.8210\n",
      "Training loss and acc: 0.2475 0.8840\n",
      "Seen so far: 32064 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6404 - accuracy: 0.8151\n",
      "Current step: 550\n",
      "Test loss and acc: 0.6404 0.8151\n",
      "Training loss and acc: 0.3078 0.8849\n",
      "Seen so far: 35264 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6054 - accuracy: 0.8252\n",
      "Current step: 600\n",
      "Test loss and acc: 0.6054 0.8252\n",
      "Training loss and acc: 0.2171 0.8859\n",
      "Seen so far: 38464 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6193 - accuracy: 0.8113\n",
      "Current step: 650\n",
      "Test loss and acc: 0.6193 0.8113\n",
      "Training loss and acc: 0.2635 0.8860\n",
      "Seen so far: 41664 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.5994 - accuracy: 0.8246\n",
      "Current step: 700\n",
      "Test loss and acc: 0.5994 0.8246\n",
      "Training loss and acc: 0.3095 0.8865\n",
      "Seen so far: 44864 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6108 - accuracy: 0.8144\n",
      "Current step: 750\n",
      "Test loss and acc: 0.6108 0.8144\n",
      "Training loss and acc: 0.3423 0.8870\n",
      "Seen so far: 48064 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6311 - accuracy: 0.8230\n",
      "Current step: 800\n",
      "Test loss and acc: 0.6311 0.8230\n",
      "Training loss and acc: 0.3365 0.8877\n",
      "Seen so far: 51264 samples\n",
      "101/101 [==============================] - 4s 39ms/step - loss: 0.6263 - accuracy: 0.8213\n",
      "Current step: 850\n",
      "Test loss and acc: 0.6263 0.8213\n",
      "Training loss and acc: 0.3811 0.8881\n",
      "Seen so far: 54464 samples\n",
      "101/101 [==============================] - 4s 38ms/step - loss: 0.6788 - accuracy: 0.7969\n",
      "Current step: 900\n",
      "Test loss and acc: 0.6788 0.7969\n",
      "Training loss and acc: 0.2311 0.8878\n",
      "Seen so far: 57664 samples\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "        # Log every 50 batches.\n",
    "        if step % 50 == 0 and step > 0:\n",
    "            test_loss_acc = model.evaluate(X_test, Y_test, batch_size=64)\n",
    "            train_loss_acc = float(loss_value), float(train_acc_metric.result()) \n",
    "            test_loss.append(test_loss_acc[0])\n",
    "            test_acc.append(test_loss_acc[1])\n",
    "            train_loss.append(train_loss_acc[0])\n",
    "            train_acc.append(train_loss_acc[1])\n",
    "            print(\"Current step: %d\" % step)\n",
    "            print(\"Test loss and acc: %.4f %.4f\" % (test_loss_acc[0], test_loss_acc[1]))\n",
    "            print(\"Training loss and acc: %.4f %.4f\" % (float(train_loss_acc[0]), float(train_loss_acc[1])))\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    train_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3641/3641 [==============================] - 5264s 1s/step - loss: 0.1923 - accuracy: 0.6471 - val_loss: 0.0822 - val_accuracy: 0.8293\n",
      "Epoch 2/5\n",
      "3641/3641 [==============================] - 4593s 1s/step - loss: 0.0688 - accuracy: 0.8599 - val_loss: 0.0570 - val_accuracy: 0.8821\n",
      "Epoch 3/5\n",
      "3641/3641 [==============================] - 3792s 1s/step - loss: 0.0459 - accuracy: 0.9075 - val_loss: 0.0515 - val_accuracy: 0.8971\n",
      "Epoch 4/5\n",
      "3641/3641 [==============================] - 3794s 1s/step - loss: 0.0368 - accuracy: 0.9269 - val_loss: 0.0518 - val_accuracy: 0.9024\n",
      "Epoch 5/5\n",
      "3641/3641 [==============================] - 3791s 1s/step - loss: 0.0321 - accuracy: 0.9384 - val_loss: 0.0545 - val_accuracy: 0.8996\n"
     ]
    }
   ],
   "source": [
    "opt = optimizers.Adam(0.001)\n",
    "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "model_history = model.fit(x = X_train, y = Y_train, epochs = 5, batch_size = 16, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3641/3641 [==============================] - 3817s 1s/step - loss: 0.0297 - accuracy: 0.9427 - val_loss: 0.0536 - val_accuracy: 0.9089\n"
     ]
    }
   ],
   "source": [
    "model_history_1 = model.fit(x = X_train, y = Y_train, epochs = 1, batch_size = 16, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Mi Notebook\\Desktop\\Audio_project\\audio_project\\Spotter_recognition\\saved_models\\AT_RNN\\assets\n",
      "Save model and weights at C:\\Users\\Mi Notebook\\Desktop\\Audio_project\\audio_project\\Spotter_recognition\\saved_models\\AT_RNN \n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"AT_RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(model_history.history['accuracy'] + model_history_1.history['accuracy'], \n",
    "         color=\"red\")\n",
    "plt.plot(model_history.history['val_accuracy'] + model_history_1.history['val_accuracy'], \n",
    "         color=\"black\", \n",
    "         linestyle=\"dashed\")\n",
    "plt.title('AT_RNN accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(\"AT_RNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history.history['accuracy'] += model_history_1.history['accuracy']\n",
    "model_history.history['val_accuracy'] += model_history_1.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_history(model_history.history, \"AT_RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.92      0.72      0.81       254\n",
      "          go       0.85      0.78      0.81       229\n",
      "        left       0.83      0.84      0.84       236\n",
      "          no       0.87      0.84      0.86       242\n",
      "         off       0.73      0.89      0.80       226\n",
      "          on       0.89      0.74      0.81       229\n",
      "       right       0.91      0.81      0.86       252\n",
      "        stop       0.95      0.86      0.90       235\n",
      "     unknown       0.93      0.97      0.95      4081\n",
      "          up       0.85      0.78      0.81       250\n",
      "         yes       0.99      0.87      0.93       239\n",
      "\n",
      "    accuracy                           0.91      6473\n",
      "   macro avg       0.88      0.83      0.85      6473\n",
      "weighted avg       0.91      0.91      0.91      6473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report(model, X_test, Y_test, lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
