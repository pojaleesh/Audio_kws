{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers, optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, MaxPool2D\n",
    "from keras import layers\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import os\n",
    "import pickle\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    \n",
    "    nclass = 14\n",
    "    \n",
    "    inp = Input(input_shape)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    out = Dense(nclass, activation='softmax')(x)\n",
    "\n",
    "    \n",
    "    ret_model = Model(inputs = inp, outputs=out)\n",
    "    \n",
    "    return ret_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictModel = make_model((30, 216, 1))\n",
    "predictModel.load_weights(\"models/Main_model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(0.001)\n",
    "predictModel.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'labels'\n",
    "infile = open(filename,'rb')\n",
    "lb = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict():\n",
    "    path = 'temp.wav'\n",
    "    X, sample_rate = librosa.load(path, res_type='kaiser_fast', duration=2.5, sr=44100, offset=0.5)\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=30)\n",
    "    if mfccs.shape[1] < 216:\n",
    "        b = np.zeros((30, 216 - mfccs.shape[1]))\n",
    "        mfccs = np.concatenate((mfccs, b), axis=1)\n",
    "    \n",
    "    mfccs = np.expand_dims(mfccs, axis=0)\n",
    "    \n",
    "    filename = 'temp_data/mean'\n",
    "    outfile = open(filename,'rb')\n",
    "    mean = pickle.load(outfile)\n",
    "    outfile.close()\n",
    "    \n",
    "    filename = 'temp_data/std'\n",
    "    outfile = open(filename,'rb')\n",
    "    std = pickle.load(outfile)\n",
    "    outfile.close()\n",
    "    \n",
    "    mfccs = (mfccs - mean) / std\n",
    "    mffcs = np.array(mfccs)\n",
    "    \n",
    "    mfccs = mfccs.reshape((mfccs.shape[0], mfccs.shape[1], mfccs.shape[2], 1))\n",
    "    newpred = predictModel.predict(mfccs, batch_size=16, verbose=1)\n",
    "    final = newpred.argmax(axis=1)\n",
    "    final = final.astype(int).flatten()\n",
    "    final = (lb.inverse_transform((final)))\n",
    "    \n",
    "    return final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
